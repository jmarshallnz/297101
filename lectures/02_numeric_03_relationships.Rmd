---
title: 'Quantitative data'
subtitle: 'Relationships'
output:
  xaringan::moon_reader:
    css: [default, default-fonts, "custom.css"]
    nature:
      highlightStyle: tomorrow
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      slideNumberFormat: |
        <div class="progress-bar-container">
          <div class="progress-bar" style="width: calc(%current% / %total% * 100%);" />
        </div>
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
library(palmerpenguins)
penguins = na.omit(penguins)
#data(package = 'palmerpenguins')
knitr::opts_chunk$set(echo = TRUE, comment = "")
knitr::opts_chunk$set(fig.dim=c(4.8, 4.5), fig.retina=2, out.width="100%")

vacc_years_to_use <- c(2012,2021)
```

## Relationships between quantitative variables

- A **scatter plot** is usually the best display for comparing quantitative variables.

- We're interested in what the trend is.

- Is it going up? Is it going down?

- Is it straight or curved?

- How closely do points cluster around the trend? Do they cluster tightly around the trend (a strong relationship)? Is the amount of clustering consistent?


---

.left-code[
## Example: Penguins

```{r peng_scatter1, eval=FALSE}
ggplot(data = penguins) +
  geom_point(
    mapping = aes(
      x = flipper_length_mm,
      y = body_mass_g
      )
    )
```

As expected, increasing flipper length means
increasing body mass.

A straight line would fit OK.

There's still quite a bit of scatter around
the line.

Flipper length doesn't explain all of body mass - other things
affect body mass too.
]

.right-plot[
```{r, ref.label="peng_scatter1", echo=FALSE, message=FALSE}
```
]

---

## Relationship between quantitative variables

We treat one variable as the **response**. This goes on the y axis.

We treat the other variable as **explanatory**. This goes on the x axis.

The response is often referred to as the **dependent** variable - indicating that it's value might depend on the value of the explanatory variable in some way, at least potentially.

The explanatory variables are referred to as being **independent** - we assume it doesn't depend on the response.

Choosing which is which is somewhat arbitrary, but there's often ways that make more sense than others. e.g. having body mass be determined
by flipper size means that we could add in other independent variables later (e.g. like height) which would also affect body mass.

---

## Scatterplot examples

```{r, echo=FALSE, fig.dim=c(8, 4.)}
set.seed(5)
x1 <- rnorm(100)
y1 <- x1 + rnorm(100, sd=0.5)
y1[13] <- 1.2
x2 <- x1
y2 <- (x2+2.5)^3 + rnorm(100, sd=10)
set.seed(7)
x3 <- rnorm(100)
y3 <- -x3 + rnorm(100, sd=0.2)
set.seed(13)
x4 <- rnorm(100)
y4 <- rnorm(100)
d <- data.frame(x=c(x1, x2, x3, x3), y=c(y1,y2,y3,y4), g=rep(1:4, each=100))
ggplot(d, aes(x=x, y=y)) + geom_point(alpha=0.6, size=2) + facet_wrap(~g, ncol=2, scales='free') +
  theme_bw() +
  theme(axis.title=element_blank(),
        axis.text=element_blank(),
        axis.ticks=element_blank(),
        strip.background = element_blank(),
        strip.text = element_blank()
        )
```

---

## Extreme observations (Outliers)

Outliers on scatter plots can be points that have extreme `x` or `y` values. These will be outliers when you look at `x` or `y` separately.

Or they could have normal `x` and `y` values, but are still extreme compared to the rest of the data due to the pairing being unusual.

The only way to see the second kind is from a scatterplot.

---

## Covariance and correlation

Just like there are numeric summaries for single quantiative variables, there are similar summaries for two variables.

The concepts of center are the same (i.e. the 'center' of a scatterplot is likely $(\bar{x}, \bar{y})$)

But we have different concepts of spread. We have $\sigma_x$ and $\sigma_y$ for the standard deviation of $x$ and $y$ but
that doesn't convey how $y$ changes with $x$ and vice-versa.

There are two additional measures we can use: **covariance** and **correlation**.

---

.left-code[
## Covariance

Recall that the **variance** of a single variable $x$ is given by:

$$
\mathsf{var}(x) = \frac{1}{n}\sum_{i=1}^n (x_i - \bar{x})^2.
$$

The **covariance** of $x$ and $y$ is given by

$$
\mathsf{cov}(x,y) = \frac{1}{n}\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y}).
$$

In RStudio, we use the `cov()` function for this.

$(x, y)$ pairs where $x$ and $y$ are both greater or both less than their mean
contribute positively to the covariance.
]

.right-plot[
```{r, echo=FALSE, warning=FALSE}
set.seed(3)
x <- rnorm(100, 0, 5)
y <- x + rnorm(100, 0, 2)

dat <- data.frame(x, y)

ggplot(dat) +
  geom_point(mapping=aes(x=x, y=y, alpha=(x - mean(x))*(y - mean(y)) > 0)) +
  geom_hline(yintercept=mean(dat$x), linetype='dashed') +
  geom_vline(xintercept=mean(dat$y), linetype='dashed') +
  scale_x_continuous(breaks=mean(dat$x), labels=expression(bar(x))) +
  scale_y_continuous(breaks=mean(dat$y), labels=expression(bar(y))) +
  theme_minimal() +
  theme(axis.ticks=element_blank(),
        panel.grid=element_blank()) +
  scale_alpha_manual(values=c(0.3,0.8), guide='none') +
  labs(x=NULL, y=NULL)
```
]
---
.left-code[
## Covariance

Recall that the **variance** of a single variable $x$ is given by:

$$
\mathsf{var}(x) = \frac{1}{n}\sum_{i=1}^n (x_i - \bar{x})^2.
$$

The **covariance** of $x$ and $y$ is given by

$$
\mathsf{cov}(x,y) = \frac{1}{n}\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y}).
$$

In RStudio, we use the `cov()` function for this.

$(x, y)$ pairs where only one of $x$ or $y$ are greater than the mean
contribute negatively to the covariance.
]

.right-plot[
```{r, echo=FALSE, warning=FALSE}
set.seed(3)
x <- rnorm(100, 0, 5)
y <- x + rnorm(100, 0, 2)

dat <- data.frame(x, y)

ggplot(dat) +
  geom_point(mapping=aes(x=x, y=y, alpha=(x - mean(x))*(y - mean(y)) < 0)) +
  geom_hline(yintercept=mean(dat$x), linetype='dashed') +
  geom_vline(xintercept=mean(dat$y), linetype='dashed') +
  scale_x_continuous(breaks=mean(dat$x), labels=expression(bar(x))) +
  scale_y_continuous(breaks=mean(dat$y), labels=expression(bar(y))) +
  theme_minimal() +
  theme(axis.ticks=element_blank(),
        panel.grid=element_blank()) +
  scale_alpha_manual(values=c(0.3,0.8), guide='none') +
  labs(x=NULL, y=NULL)
```
]

---
.left-code[
## Covariance

Recall that the **variance** of a single variable $x$ is given by:

$$
\mathsf{var}(x) = \frac{1}{n}\sum_{i=1}^n (x_i - \bar{x})^2.
$$

The **covariance** of $x$ and $y$ is given by

$$
\mathsf{cov}(x,y) = \frac{1}{n}\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y}).
$$

In RStudio, we use the `cov()` function for this.

$(x, y)$ pairs where only one of $x$ or $y$ are greater than the mean
contribute negatively to the covariance.
]

.right-plot[
```{r, echo=FALSE, warning=FALSE}
set.seed(3)
x <- rnorm(100, 0, 5)
y <- -x + rnorm(100, 0, 3)

dat_neg <- data.frame(x, y)

ggplot(dat_neg) +
  geom_point(mapping=aes(x=x, y=y, alpha=(x - mean(x))*(y - mean(y)) < 0)) +
  geom_hline(yintercept=mean(dat_neg$x), linetype='dashed') +
  geom_vline(xintercept=mean(dat_neg$y), linetype='dashed') +
  scale_x_continuous(breaks=mean(dat_neg$x), labels=expression(bar(x))) +
  scale_y_continuous(breaks=mean(dat_neg$y), labels=expression(bar(y))) +
  theme_minimal() +
  theme(axis.ticks=element_blank(),
        panel.grid=element_blank()) +
  scale_alpha_manual(values=c(0.3,0.8), guide='none') +
  labs(x=NULL, y=NULL)
```
]

---
.left-code[
## Covariance

Recall that the **variance** of a single variable $x$ is given by:

$$
\mathsf{var}(x) = \frac{1}{n}\sum_{i=1}^n (x_i - \bar{x})^2.
$$

The **covariance** of $x$ and $y$ is given by

$$
\mathsf{cov}(x,y) = \frac{1}{n}\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y}).
$$

In RStudio, we use the `cov()` function for this.

Where the quadrants balance, the covariance is 0.
]

.right-plot[
```{r, echo=FALSE, warning=FALSE}
set.seed(3)
x <- rnorm(100, 0, 5)
y <- rnorm(100, 0, 5)

dat <- data.frame(x, y)

ggplot(dat) +
  geom_point(mapping=aes(x=x, y=y, alpha=(x - mean(x))*(y - mean(y)) < 0)) +
  geom_hline(yintercept=mean(dat$x), linetype='dashed') +
  geom_vline(xintercept=mean(dat$y), linetype='dashed') +
  scale_x_continuous(breaks=mean(dat$x), labels=expression(bar(x))) +
  scale_y_continuous(breaks=mean(dat$y), labels=expression(bar(y))) +
  theme_minimal() +
  theme(axis.ticks=element_blank(),
        panel.grid=element_blank()) +
  scale_alpha_manual(values=c(0.3,0.8), guide='none') +
  labs(x=NULL, y=NULL)
```
]

---

## Correlation

The **correlation** of $x$ and $y$ is given as

$$
\mathsf{cor}(x,y) = \frac{\mathsf{cov}(x,y)}{\mathsf{sd}(x)\mathsf{sd}(y)}
$$

The division by the standard deviations ensures that correlation is not affected by scale: Multiply $x$ by 5 and you'll get the same correlation.

The correlation is also not affected by center: Add 1000 to $y$ and you'll get the same correlation.

It is also symmetric:

$$
\mathsf{cor}(x,y) = \mathsf{cor}(y,x).
$$

In RStudio, we use the `cor()` function for this.

---

.left-code[
## Example: Penguins

```{r peng_corr1}
summarise(penguins,
          cov = cov(
            flipper_length_mm,
            body_mass_g
          ),
          r = cor(
            flipper_length_mm,
            body_mass_g
          )
        )
```

]

.right-plot[
```{r echo=FALSE, message=FALSE}
ggplot(data = penguins) +
  geom_point(
    mapping = aes(
      x = flipper_length_mm,
      y = body_mass_g
      )
    )
```
]


---

## Correlation

The correlation coefficient is sometimes represented by $\rho$ or $r$.

It measures the amount that $y$ depends on $x$ through a **straight-line relationship**.

It is always in the range -1 to 1.

 - A value of 1 indicates a perfect, positive straight line relationship.

 - A value of -1 indicates a perfect, negative straight line relationship.

 - A value of 0 indicates no relationship at all.

If the data don't look as though a straight line would be appropriate, then the correlation coefficient might not be what you want.

**Always look at your data**

---

```{r, echo=FALSE, fig.dim=c(8,4.8), fig.retina=3}
library(mvtnorm)
library(tidyverse)
rho <- data.frame(rho = c(0.95, 0.9, 0.6, 0.3, 0, -0.3, -0.6, -0.9, -0.95))
mu <-c(0,0)
rcorr <- function(rho, n) {
  dat <- rmvnorm(n, sigma = matrix(c(1, rho, rho, 1),2))
  while (abs(cor(dat[,1], dat[,2])-rho) > 0.01) {
    dat <- rmvnorm(n, sigma = matrix(c(1, rho, rho, 1),2))
  }
  data.frame(x = dat[,1], y = dat[,2])
}
dat <- rho |> mutate(data = map(rho, rcorr, n=100)) |>
  unnest(data)

ggplot(dat) +
  geom_point(aes(x=x, y=y)) +
  facet_wrap(~rho, scales='free', labeller = function(x) { lapply(x, function(x) { paste0('r = ', x) }) }) +
  theme_bw() +
  theme(axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())
```

---

.left-code[
## Beware, Dinosaurs!

All these datasets have the same
correlation.

And the same means for $x$ and $y$

And the same standard deviations!

**`r` only makes sense for straight-line data**
]

.right-plot[
<img src="graphics/datasaurus.gif" width="100%" />
]

---

## Key ideas

- The interesting thing when you have two numeric measures is how they change together.

- Best chart is a scatterplot.

- Talk about what the trend is (what is the shape? is it linear or curved?)

- Also talk about the spread around the trend - smaller spread means stronger trend.

- Summarise in terms of correlation **only if the data are linear**.
